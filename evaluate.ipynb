{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 16:35:34.120951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-24 16:35:34.120972: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mat73\n",
    "from tensorflow.keras.models import load_model\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 16:35:37.877935: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-24 16:35:37.877959: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-24 16:35:37.877982: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (thanos): /proc/driver/nvidia/version does not exist\n",
      "2022-03-24 16:35:37.878183: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-24 16:35:38.030964: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 138444800 exceeds 10% of free system memory.\n",
      "2022-03-24 16:35:38.083089: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 138444800 exceeds 10% of free system memory.\n",
      "2022-03-24 16:35:38.110016: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 138444800 exceeds 10% of free system memory.\n",
      "2022-03-24 16:35:38.657655: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 138444800 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model_filename = '../Best Neural Nets/eeg_cnn_21.h5'\n",
    "model = load_model(model_filename,  compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create simulated data (with AWGN) for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### single source ######################\n",
    "from forward import solve_forward\n",
    "from simulation import Simulation\n",
    "\n",
    "fwd = solve_forward(num_dipoles='10k')\n",
    "sim = Simulation(fwd=fwd, source_data=None, eeg_data=None)\n",
    "snr = 20\n",
    "eeg_noisy, sources = sim.create_evaluate_dataset(n_samples=5000, snr=snr)\n",
    "\n",
    "print(eeg_noisy.shape)\n",
    "# np.save('./eval_sim_data/single_source/{}db/eeg_noisy.npy'.format(snr),eeg_noisy)\n",
    "# np.save('./eval_sim_data/single_source/{}db/sources.npy'.format(snr),sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### two sources ######################\n",
    "from forward import solve_forward\n",
    "from simulation import Simulation\n",
    "\n",
    "fwd = solve_forward(num_dipoles='10k')\n",
    "settings = {  'number_of_sources': 2 }\n",
    "snr = 20\n",
    "sim = Simulation(fwd=fwd, settings=settings, noisy_eeg=True,target_snr=(True, snr))\n",
    "sim.simulate(n_samples=5000)\n",
    "\n",
    "eeg_noisy = sim.eeg_data\n",
    "sources = sim.source_data\n",
    "source_centers = sim.source_centers\n",
    "\n",
    "print(eeg_noisy.shape)\n",
    "# np.save('./eval_sim_data/two_sources/{}db/eeg_noisy.npy'.format(snr),eeg_noisy)\n",
    "# np.save('./eval_sim_data/two_sources/{}db/sources.npy'.format(snr),sources)\n",
    "# np.save('./eval_sim_data/two_sources/{}db/source_centers.npy'.format(snr),source_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval with noisy sim data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topos were generated with matlab with file create_cnn_input.\n",
    "sources_path = 'single_source'\n",
    "snr = 20\n",
    "eeg_topos = mat73.loadmat('./eval_sim_data/{}/{}db/eeg_topos_noisy.mat'.format(sources_path,snr))['eeg_topos']\n",
    "eeg_topos = eeg_topos.transpose(2,0,1)\n",
    "predicted_sources = model.predict(eeg_topos).T\n",
    "np.save('./eval_sim_data/{}/{}db/predicted_sources.npy'.format(sources_path,snr),predicted_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms='20'\n",
    "real_data_file = './real_data/{}ms/eeg_topo_real_{}ms.mat'.format(ms,ms)\n",
    "topos_eval =  scipy.io.loadmat(real_data_file)['Zi'] \n",
    "\n",
    "plt.contourf(topos_eval, cmap=cm.get_cmap('viridis'))\n",
    "cbar = plt.colorbar()\n",
    "plt.title('Topography for {} ms'.format(ms.replace('_','.')))\n",
    "plt.show()\n",
    "\n",
    "topos_eval= np.expand_dims(topos_eval, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topos_eval = mat73.loadmat('../../Downloads/one_two_sources/eeg_topos.mat')['eeg_topos']\n",
    "topos_eval = topos_eval.transpose(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sources = model.predict(topos_eval).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../Downloads/pred_real.npy',predicted_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./real_data/{}ms/pred_sources_{}.npy'.format(ms,ms),predicted_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval with depth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5ec991572d4310a25eba5779363ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "snr = 20\n",
    "path_to_depth = './eval_sim_data/depth/{}db/'.format(snr)\n",
    "\n",
    "for depth_folder in tqdm(os.listdir(path_to_depth)):\n",
    "    depth_folder_full = os.path.join(path_to_depth, depth_folder)\n",
    "    topos_eval = mat73.loadmat(os.path.join(depth_folder_full,'eeg_topos.mat'))['eeg_topos']\n",
    "\n",
    "    topos_eval = topos_eval.transpose(2,0,1)\n",
    "    predicted_sources = model.predict(topos_eval).T\n",
    "    np.save(os.path.join(depth_folder_full,'predicted_sources.npy'),predicted_sources)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e55ae3f6af515937c0319b16e610f5fb778062060e5992134dbdbaaf9a7f178e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
