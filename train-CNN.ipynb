{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 00:39:18.852177: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-21 00:39:18.852209: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from forward import solve_forward\n",
    "from simulation import Simulation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "# to load large .mat files\n",
    "import mat73\n",
    "import random\n",
    "from net import EEG_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_topos = mat73.loadmat('/media/thanos/Elements/thanos/sim_data/sim_type_1/eeg_topos_2TeD.mat')['eeg_topos']\n",
    "eeg_topos = eeg_topos.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Topography for eeg signal: 64013')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "topo_idx = random.randint(0,eeg_topos.shape[0]-1)\n",
    "topo = eeg_topos[topo_idx,:,:]\n",
    "plt.contourf(topo, cmap=cm.get_cmap('viridis'))\n",
    "cbar = plt.colorbar()\n",
    "plt.draw()\n",
    "plt.title('Topography for eeg signal: {}'.format(topo_idx+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward problem is solved.\n",
      "Electrodes: (73, 3)\n",
      "Dipoles: (50460, 3)\n",
      "Leadfield: (73, 50460)\n"
     ]
    }
   ],
   "source": [
    "# load previous simulation\n",
    "sources = np.load('/media/thanos/Elements/thanos/sim_data/sim_type_1/sources_2TeD.npy')\n",
    "eeg = np.load('/media/thanos/Elements/thanos/sim_data/sim_type_1/eeg_2TeD.npy')\n",
    "\n",
    "fwd = solve_forward()\n",
    "sim = Simulation(fwd=fwd, source_data=sources, eeg_data=eeg)\n",
    "# fwd = solve_forward()\n",
    "# sim = Simulation(fwd=fwd)\n",
    "# sim.simulate(n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegcnn = EEG_CNN(sim=sim, eeg_topographies=eeg_topos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 00:48:54.001863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-21 00:48:54.002969: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-21 00:48:54.004210: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (thanos): /proc/driver/nvidia/version does not exist\n",
      "2021-12-21 00:48:54.021387: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-21 00:48:54.853436: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 276889600 exceeds 10% of free system memory.\n",
      "2021-12-21 00:48:55.204725: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 276889600 exceeds 10% of free system memory.\n",
      "2021-12-21 00:48:55.596874: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 276889600 exceeds 10% of free system memory.\n",
      "2021-12-21 00:48:56.745808: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 413368320 exceeds 10% of free system memory.\n",
      "2021-12-21 00:48:56.922990: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 413368320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 65, 65, 32)        320       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 135200)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               69222912  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              2099200   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " OutputLayer (Dense)         (None, 50460)             103392540 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,254,620\n",
      "Trainable params: 175,247,452\n",
      "Non-trainable params: 7,168\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "eegcnn.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "631/631 [==============================] - 1539s 2s/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 2/120\n",
      "631/631 [==============================] - 1497s 2s/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 3/120\n",
      "631/631 [==============================] - 1538s 2s/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 4/120\n",
      "631/631 [==============================] - 1515s 2s/step - loss: 8.5222e-04 - val_loss: 9.3354e-04\n",
      "Epoch 5/120\n",
      "631/631 [==============================] - 1445s 2s/step - loss: 7.0316e-04 - val_loss: 7.4371e-04\n",
      "Epoch 6/120\n",
      "631/631 [==============================] - 1416s 2s/step - loss: 6.0063e-04 - val_loss: 7.9645e-04\n",
      "Epoch 7/120\n",
      "631/631 [==============================] - 1453s 2s/step - loss: 5.3881e-04 - val_loss: 7.1278e-04\n",
      "Epoch 8/120\n",
      "631/631 [==============================] - 1478s 2s/step - loss: 4.9099e-04 - val_loss: 5.1407e-04\n",
      "Epoch 9/120\n",
      "631/631 [==============================] - 1502s 2s/step - loss: 4.5495e-04 - val_loss: 5.7648e-04\n",
      "Epoch 10/120\n",
      "631/631 [==============================] - 1480s 2s/step - loss: 4.0264e-04 - val_loss: 6.0479e-04\n",
      "Epoch 11/120\n",
      "631/631 [==============================] - 1431s 2s/step - loss: 3.8554e-04 - val_loss: 7.1758e-04\n",
      "Epoch 12/120\n",
      "631/631 [==============================] - 1417s 2s/step - loss: 3.6543e-04 - val_loss: 4.4435e-04\n",
      "Epoch 13/120\n",
      "631/631 [==============================] - 1401s 2s/step - loss: 3.3791e-04 - val_loss: 3.7865e-04\n",
      "Epoch 14/120\n",
      "631/631 [==============================] - 1418s 2s/step - loss: 3.1923e-04 - val_loss: 4.4132e-04\n",
      "Epoch 15/120\n",
      "631/631 [==============================] - 1409s 2s/step - loss: 2.9837e-04 - val_loss: 3.9161e-04\n",
      "Epoch 16/120\n",
      "631/631 [==============================] - 1387s 2s/step - loss: 2.8323e-04 - val_loss: 3.4332e-04\n",
      "Epoch 17/120\n",
      "631/631 [==============================] - 1390s 2s/step - loss: 2.6353e-04 - val_loss: 3.5184e-04\n",
      "Epoch 18/120\n",
      "631/631 [==============================] - 1387s 2s/step - loss: 2.5573e-04 - val_loss: 3.1805e-04\n",
      "Epoch 19/120\n",
      "631/631 [==============================] - 1374s 2s/step - loss: 2.4056e-04 - val_loss: 2.8301e-04\n",
      "Epoch 20/120\n",
      "631/631 [==============================] - 1381s 2s/step - loss: 2.2566e-04 - val_loss: 2.5758e-04\n",
      "Epoch 21/120\n",
      "631/631 [==============================] - 1378s 2s/step - loss: 2.2367e-04 - val_loss: 2.4868e-04\n",
      "Epoch 22/120\n",
      "631/631 [==============================] - 1373s 2s/step - loss: 2.1174e-04 - val_loss: 2.3084e-04\n",
      "Epoch 23/120\n",
      "631/631 [==============================] - 1370s 2s/step - loss: 2.0495e-04 - val_loss: 6.7942e-04\n",
      "Epoch 24/120\n",
      "631/631 [==============================] - 1369s 2s/step - loss: 1.9516e-04 - val_loss: 2.1696e-04\n",
      "Epoch 25/120\n",
      "631/631 [==============================] - 1371s 2s/step - loss: 1.8527e-04 - val_loss: 4.0473e-04\n",
      "Epoch 26/120\n",
      "631/631 [==============================] - 1367s 2s/step - loss: 1.8885e-04 - val_loss: 2.4686e-04\n",
      "Epoch 27/120\n",
      "631/631 [==============================] - 1404s 2s/step - loss: 1.7630e-04 - val_loss: 2.4040e-04\n",
      "Epoch 28/120\n",
      "631/631 [==============================] - 1410s 2s/step - loss: 1.7234e-04 - val_loss: 4.4654e-04\n",
      "Epoch 29/120\n",
      "631/631 [==============================] - 1408s 2s/step - loss: 1.5808e-04 - val_loss: 2.1314e-04\n",
      "Epoch 30/120\n",
      "631/631 [==============================] - 1405s 2s/step - loss: 1.5852e-04 - val_loss: 1.8968e-04\n",
      "Epoch 31/120\n",
      "631/631 [==============================] - 1382s 2s/step - loss: 1.5601e-04 - val_loss: 1.7940e-04\n",
      "Epoch 32/120\n",
      "631/631 [==============================] - 1380s 2s/step - loss: 1.4904e-04 - val_loss: 3.7424e-04\n",
      "Epoch 33/120\n",
      "631/631 [==============================] - 1455s 2s/step - loss: 1.4969e-04 - val_loss: 2.4055e-04\n",
      "Epoch 34/120\n",
      "631/631 [==============================] - 1444s 2s/step - loss: 1.4495e-04 - val_loss: 2.1923e-04\n",
      "Epoch 35/120\n",
      "631/631 [==============================] - 1304s 2s/step - loss: 1.3722e-04 - val_loss: 1.4054e-04\n",
      "Epoch 36/120\n",
      "631/631 [==============================] - 1384s 2s/step - loss: 1.4445e-04 - val_loss: 2.1697e-04\n",
      "Epoch 37/120\n",
      "631/631 [==============================] - 1443s 2s/step - loss: 1.3426e-04 - val_loss: 1.9098e-04\n",
      "Epoch 38/120\n",
      "631/631 [==============================] - 1438s 2s/step - loss: 1.2699e-04 - val_loss: 2.1664e-04\n",
      "Epoch 39/120\n",
      "631/631 [==============================] - 1481s 2s/step - loss: 1.2917e-04 - val_loss: 1.6896e-04\n",
      "Epoch 40/120\n",
      "631/631 [==============================] - 1489s 2s/step - loss: 1.2359e-04 - val_loss: 1.5180e-04\n",
      "Epoch 41/120\n",
      "631/631 [==============================] - 1562s 2s/step - loss: 1.2254e-04 - val_loss: 1.5680e-04\n",
      "Epoch 42/120\n",
      "631/631 [==============================] - 1558s 2s/step - loss: 1.1663e-04 - val_loss: 1.6054e-04\n",
      "Epoch 43/120\n",
      "631/631 [==============================] - 1560s 2s/step - loss: 1.1482e-04 - val_loss: 1.7785e-04\n",
      "Epoch 44/120\n",
      "631/631 [==============================] - 1560s 2s/step - loss: 1.1412e-04 - val_loss: 1.5725e-04\n",
      "Epoch 45/120\n",
      "631/631 [==============================] - 1568s 2s/step - loss: 1.1116e-04 - val_loss: 1.9280e-04\n",
      "Epoch 46/120\n",
      "631/631 [==============================] - 1477s 2s/step - loss: 1.1149e-04 - val_loss: 1.9042e-04\n",
      "Epoch 47/120\n",
      "631/631 [==============================] - 1499s 2s/step - loss: 1.0946e-04 - val_loss: 1.3855e-04\n",
      "Epoch 48/120\n",
      "631/631 [==============================] - 1527s 2s/step - loss: 1.0674e-04 - val_loss: 1.0331e-04\n",
      "Epoch 49/120\n",
      "631/631 [==============================] - 1538s 2s/step - loss: 1.0374e-04 - val_loss: 1.3015e-04\n",
      "Epoch 50/120\n",
      "631/631 [==============================] - 1586s 3s/step - loss: 1.0441e-04 - val_loss: 1.2312e-04\n",
      "Epoch 51/120\n",
      "631/631 [==============================] - 1603s 3s/step - loss: 1.0094e-04 - val_loss: 1.2937e-04\n",
      "Epoch 52/120\n",
      "631/631 [==============================] - 1615s 3s/step - loss: 9.9423e-05 - val_loss: 1.1551e-04\n",
      "Epoch 53/120\n",
      "631/631 [==============================] - 1649s 3s/step - loss: 9.8077e-05 - val_loss: 9.6709e-05\n",
      "Epoch 54/120\n",
      "631/631 [==============================] - 1694s 3s/step - loss: 9.8250e-05 - val_loss: 1.2085e-04\n",
      "Epoch 55/120\n",
      "631/631 [==============================] - 1753s 3s/step - loss: 9.1698e-05 - val_loss: 1.3038e-04\n",
      "Epoch 56/120\n",
      "631/631 [==============================] - 1619s 3s/step - loss: 9.5073e-05 - val_loss: 1.3539e-04\n",
      "Epoch 57/120\n",
      "631/631 [==============================] - 1637s 3s/step - loss: 9.0871e-05 - val_loss: 1.2079e-04\n",
      "Epoch 58/120\n",
      "631/631 [==============================] - 1693s 3s/step - loss: 9.1240e-05 - val_loss: 1.0781e-04\n",
      "Epoch 59/120\n",
      "631/631 [==============================] - 1725s 3s/step - loss: 8.8138e-05 - val_loss: 1.2725e-04\n",
      "Epoch 60/120\n",
      "631/631 [==============================] - 1709s 3s/step - loss: 8.8565e-05 - val_loss: 1.2481e-04\n",
      "Epoch 61/120\n",
      "631/631 [==============================] - 1715s 3s/step - loss: 8.8098e-05 - val_loss: 1.2758e-04\n",
      "Epoch 62/120\n",
      "631/631 [==============================] - 1609s 3s/step - loss: 8.6291e-05 - val_loss: 2.5297e-04\n",
      "Epoch 63/120\n",
      "631/631 [==============================] - 1605s 3s/step - loss: 8.6175e-05 - val_loss: 1.2165e-04\n",
      "Epoch 64/120\n",
      "631/631 [==============================] - 1601s 3s/step - loss: 8.8340e-05 - val_loss: 1.0172e-04\n",
      "Epoch 65/120\n",
      "631/631 [==============================] - 1598s 3s/step - loss: 8.3114e-05 - val_loss: 1.1386e-04\n",
      "Epoch 66/120\n",
      "631/631 [==============================] - 1595s 3s/step - loss: 8.2380e-05 - val_loss: 1.0737e-04\n",
      "Epoch 67/120\n",
      "631/631 [==============================] - 1590s 3s/step - loss: 8.0752e-05 - val_loss: 1.2574e-04\n",
      "Epoch 68/120\n",
      "631/631 [==============================] - 1609s 3s/step - loss: 8.0836e-05 - val_loss: 8.0601e-05\n",
      "Epoch 69/120\n",
      "631/631 [==============================] - 1586s 3s/step - loss: 8.0113e-05 - val_loss: 1.0288e-04\n",
      "Epoch 70/120\n",
      "631/631 [==============================] - 1591s 3s/step - loss: 7.8966e-05 - val_loss: 7.8130e-05\n",
      "Epoch 71/120\n",
      "631/631 [==============================] - 1594s 3s/step - loss: 7.6705e-05 - val_loss: 1.3174e-04\n",
      "Epoch 72/120\n",
      "631/631 [==============================] - 1575s 2s/step - loss: 7.7946e-05 - val_loss: 1.8304e-04\n",
      "Epoch 73/120\n",
      "631/631 [==============================] - 1567s 2s/step - loss: 7.5686e-05 - val_loss: 7.5164e-05\n",
      "Epoch 74/120\n",
      "631/631 [==============================] - 1575s 2s/step - loss: 7.5144e-05 - val_loss: 1.6412e-04\n",
      "Epoch 75/120\n",
      "631/631 [==============================] - 1555s 2s/step - loss: 7.4018e-05 - val_loss: 8.9854e-05\n",
      "Epoch 76/120\n",
      "631/631 [==============================] - 1558s 2s/step - loss: 7.3550e-05 - val_loss: 1.3835e-04\n",
      "Epoch 77/120\n",
      "631/631 [==============================] - 1551s 2s/step - loss: 7.1943e-05 - val_loss: 7.7900e-05\n",
      "Epoch 78/120\n",
      "631/631 [==============================] - 1552s 2s/step - loss: 7.1167e-05 - val_loss: 7.4840e-05\n",
      "Epoch 79/120\n",
      "631/631 [==============================] - 1553s 2s/step - loss: 7.2731e-05 - val_loss: 7.1100e-05\n",
      "Epoch 80/120\n",
      "631/631 [==============================] - 1545s 2s/step - loss: 6.9391e-05 - val_loss: 1.0188e-04\n",
      "Epoch 81/120\n",
      "631/631 [==============================] - 1548s 2s/step - loss: 7.0770e-05 - val_loss: 8.3170e-05\n",
      "Epoch 82/120\n",
      "631/631 [==============================] - 1543s 2s/step - loss: 7.0651e-05 - val_loss: 9.6058e-05\n",
      "Epoch 83/120\n",
      "631/631 [==============================] - 1530s 2s/step - loss: 6.8558e-05 - val_loss: 7.5399e-05\n",
      "Epoch 84/120\n",
      "631/631 [==============================] - 1426s 2s/step - loss: 6.9403e-05 - val_loss: 1.3069e-04\n",
      "Epoch 85/120\n",
      "631/631 [==============================] - 1408s 2s/step - loss: 6.9156e-05 - val_loss: 8.0237e-05\n",
      "Epoch 86/120\n",
      "631/631 [==============================] - 1463s 2s/step - loss: 6.5953e-05 - val_loss: 1.2690e-04\n",
      "Epoch 87/120\n",
      "631/631 [==============================] - 1400s 2s/step - loss: 6.8275e-05 - val_loss: 6.2999e-05\n",
      "Epoch 88/120\n",
      "631/631 [==============================] - 1444s 2s/step - loss: 6.5727e-05 - val_loss: 7.6834e-05\n",
      "Epoch 89/120\n",
      "631/631 [==============================] - 1457s 2s/step - loss: 6.5035e-05 - val_loss: 7.8663e-05\n",
      "Epoch 90/120\n",
      "631/631 [==============================] - 1490s 2s/step - loss: 6.4485e-05 - val_loss: 7.3564e-05\n",
      "Epoch 91/120\n",
      "631/631 [==============================] - 1441s 2s/step - loss: 6.3492e-05 - val_loss: 7.7538e-05\n",
      "Epoch 92/120\n",
      "631/631 [==============================] - 1437s 2s/step - loss: 6.2260e-05 - val_loss: 1.0636e-04\n",
      "Epoch 93/120\n",
      "631/631 [==============================] - 1450s 2s/step - loss: 6.3017e-05 - val_loss: 6.7269e-05\n",
      "Epoch 94/120\n",
      "631/631 [==============================] - 1492s 2s/step - loss: 6.2096e-05 - val_loss: 7.2035e-05\n",
      "Epoch 95/120\n",
      "631/631 [==============================] - 1516s 2s/step - loss: 6.1093e-05 - val_loss: 6.3886e-05\n",
      "Epoch 96/120\n",
      "631/631 [==============================] - 1484s 2s/step - loss: 6.1097e-05 - val_loss: 6.3709e-05\n",
      "Epoch 97/120\n",
      "631/631 [==============================] - 1428s 2s/step - loss: 6.1142e-05 - val_loss: 1.0870e-04\n",
      "Epoch 98/120\n",
      "631/631 [==============================] - 1418s 2s/step - loss: 5.9841e-05 - val_loss: 7.2198e-05\n",
      "Epoch 99/120\n",
      "631/631 [==============================] - 1397s 2s/step - loss: 5.9813e-05 - val_loss: 8.9242e-05\n",
      "Epoch 100/120\n",
      "631/631 [==============================] - 1440s 2s/step - loss: 6.1251e-05 - val_loss: 7.9361e-05\n",
      "Epoch 101/120\n",
      "631/631 [==============================] - 1462s 2s/step - loss: 5.9336e-05 - val_loss: 1.0452e-04\n",
      "Epoch 102/120\n",
      "631/631 [==============================] - 1487s 2s/step - loss: 6.0281e-05 - val_loss: 6.5453e-05\n",
      "Epoch 103/120\n",
      "631/631 [==============================] - 1557s 2s/step - loss: 5.8335e-05 - val_loss: 8.8806e-05\n",
      "Epoch 104/120\n",
      "631/631 [==============================] - 1547s 2s/step - loss: 5.8988e-05 - val_loss: 5.8426e-05\n",
      "Epoch 105/120\n",
      "631/631 [==============================] - 1585s 2s/step - loss: 5.6939e-05 - val_loss: 6.9955e-05\n",
      "Epoch 106/120\n",
      "631/631 [==============================] - 1592s 3s/step - loss: 5.6934e-05 - val_loss: 7.0476e-05\n",
      "Epoch 107/120\n",
      "631/631 [==============================] - 1588s 3s/step - loss: 5.5706e-05 - val_loss: 9.6520e-05\n",
      "Epoch 108/120\n",
      "631/631 [==============================] - 1533s 2s/step - loss: 5.7824e-05 - val_loss: 6.1989e-05\n",
      "Epoch 109/120\n",
      "631/631 [==============================] - 1554s 2s/step - loss: 5.4991e-05 - val_loss: 9.2761e-05\n",
      "Epoch 110/120\n",
      "631/631 [==============================] - 1578s 2s/step - loss: 5.6327e-05 - val_loss: 9.2071e-05\n",
      "Epoch 111/120\n",
      "631/631 [==============================] - 1442s 2s/step - loss: 5.5643e-05 - val_loss: 7.8637e-05\n",
      "Epoch 112/120\n",
      "631/631 [==============================] - 1355s 2s/step - loss: 5.5211e-05 - val_loss: 5.4856e-05\n",
      "Epoch 113/120\n",
      "631/631 [==============================] - 1332s 2s/step - loss: 5.6347e-05 - val_loss: 6.1443e-05\n",
      "Epoch 114/120\n",
      "631/631 [==============================] - 1397s 2s/step - loss: 5.4434e-05 - val_loss: 7.2443e-05\n",
      "Epoch 115/120\n",
      "631/631 [==============================] - 1452s 2s/step - loss: 5.3376e-05 - val_loss: 8.6028e-05\n",
      "Epoch 116/120\n",
      "631/631 [==============================] - 1452s 2s/step - loss: 5.2347e-05 - val_loss: 6.2410e-05\n",
      "Epoch 117/120\n",
      "631/631 [==============================] - 1468s 2s/step - loss: 5.3731e-05 - val_loss: 8.0023e-05\n",
      "Epoch 118/120\n",
      "631/631 [==============================] - 1500s 2s/step - loss: 5.2542e-05 - val_loss: 9.1913e-05\n",
      "Epoch 119/120\n",
      "631/631 [==============================] - 1486s 2s/step - loss: 5.2793e-05 - val_loss: 5.4379e-05\n",
      "Epoch 120/120\n",
      "631/631 [==============================] - 1481s 2s/step - loss: 5.1800e-05 - val_loss: 6.1287e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.callbacks.History at 0x7f01ccae3ca0>,\n",
       " 'logs/CNN-Model-21_12_2021__00:39:21')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegcnn.fit(epochs=120, patience=35, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegcnn.save_nn('../cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegcnn.load_nn('/media/thanos/Elements/thanos/nn_trained/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_topos_eval = mat73.loadmat('/media/thanos/Elements/thanos/sim_data/sim_type_1/eval_100/eeg_topos_eval_100.mat')['eeg_topos']\n",
    "eeg_topos_eval = eeg_topos_eval.transpose(2, 0, 1)\n",
    "\n",
    "sources_eval = np.load('/media/thanos/Elements/thanos/sim_data/sim_type_1/eval_100/sources.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sources = eegcnn.predict(eeg=eeg_topos_eval).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../Downloads/predicted_sources.npy',predicted_sources)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e55ae3f6af515937c0319b16e610f5fb778062060e5992134dbdbaaf9a7f178e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
